{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5319148936170213\n",
      "Accuracy:  0.6170212765957447\n",
      "Accuracy:  0.6808510638297872\n",
      "Accuracy:  0.5106382978723404\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv) \n",
    "import numpy as np #linear algebra   \n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "#import accurecy_library for scoring attributes\n",
    "from sklearn.metrics import accuracy_score\n",
    "#importing the dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\Ariful\\\\Desktop\\\\final data\\\\thesisfinaldata1.csv')\n",
    "\n",
    "#filling null value as 0\n",
    "df=df.fillna('0')\n",
    "\n",
    "#Dropping Age column\n",
    "df = df.drop(['Age'], axis= 1)\n",
    "df = df.drop(['Age2'], axis= 1)\n",
    "#Dropping Perm_Address column\n",
    "df = df.drop(['Perm_Address'], axis= 1)\n",
    "\n",
    "#taking independent variable\n",
    "X = df.iloc[:,1:22].values\n",
    "#taking dependent variable\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "#print(\"\\nX before making numerical: \\n\",X)\n",
    "#print(\"\\ny before making numerical: \\n\",y)\n",
    "\n",
    "#taking careof categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "for i in range(0,21):\n",
    "    X[:,i]= labelencoder_X.fit_transform(X[:,i])\n",
    "\n",
    "labelencoder_y = LabelEncoder()\n",
    "y= labelencoder_y.fit_transform(y)\n",
    "#print(\"\\nX after making numerical: \\n\",X)\n",
    "#print(\"\\ny after making numerical: \\n\",y)\n",
    "\n",
    "\n",
    "#df.head(5) # head method show only first 5 rows\n",
    "for i in range(1,5):\n",
    "    # split data train 90 % and test 10 %\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    #X_train=X,y_train=y\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state = i)\n",
    "\n",
    "    #import support vector machine classifier\n",
    "    from sklearn.svm import SVC \n",
    "    #taking different peremater for support vector machine classifier\n",
    "    svclassifier =OneVsRestClassifier(svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,decision_function_shape=None, degree=3, gamma='auto', kernel='linear',max_iter=-1, probability=False, random_state=None, shrinking=True,tol=0.001, verbose=False))\n",
    "    #fitting is equal to training. Then, after it is trained, the model can be used to make predictions, usually with a .predict() method call.\n",
    "    y_score = svclassifier.fit(X_train, y_train).decision_function(X_test)\n",
    "    \n",
    "    #find out the predicted value\n",
    "    predicted = svclassifier.predict(X_test) \n",
    "\n",
    "    #print(\"Prediction Result: \",predicted)\n",
    "\n",
    "    #finding actual prediction compared with test size\n",
    "    print(\"Accuracy: \",accuracy_score(y_test, predicted, normalize = True)) #accuracy_score(train output, predict output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         1\n",
      "          2       0.41      0.82      0.55        11\n",
      "          7       0.00      0.00      0.00         1\n",
      "          9       0.00      0.00      0.00         1\n",
      "         10       0.00      0.00      0.00         2\n",
      "         11       0.00      0.00      0.00         1\n",
      "         16       0.00      0.00      0.00         1\n",
      "         17       0.00      0.00      0.00         1\n",
      "         20       0.00      0.00      0.00         1\n",
      "         24       0.00      0.00      0.00         2\n",
      "         26       0.00      0.00      0.00         5\n",
      "         27       0.60      0.79      0.68        19\n",
      "\n",
      "avg / total       0.34      0.51      0.40        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ariful\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#import library for classification report, confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "#print(confusion_matrix(y_test,predicted))  \n",
    "print(classification_report(y_test,predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ariful\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5986769365753194\n",
      "[0.47619048 0.4893617  0.55813953 0.6        0.74358974 0.57894737\n",
      " 0.67567568 0.59459459 0.59459459 0.67567568]\n"
     ]
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#estimator = object, step = int or float, optional(default = 1), cv = int, cross-validation or an iterable optional\n",
    "#scoring = string, callable or none, optional, default = none \n",
    "accuracies = cross_val_score(estimator = svclassifier, X = X_train, y = y_train, cv = 10)\n",
    "#taking 10 cv result and find mean value\n",
    "a=accuracies.mean()\n",
    "print(a)\n",
    "print(accuracies)\n",
    "#accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  2 27  2  2  2 27 27 27 27 27 27 27 27 27  2  2 27  2 27 27 27  2  2\n",
      "  2  2  2  2 27 27  2  2 27 27  2  2  2 27 27  2  2 27 27  2 27 27 27]\n",
      "[20  2 27  7 26 11 27 24 27  2 27  0 24 27 17 27 26  2  2 10 27 27 10 27\n",
      "  2  2 26  2 27 27  2  2 27 16  2 26  2 27 27 27  9 27 27 27  1 26 27]\n"
     ]
    }
   ],
   "source": [
    "#printing predicted and actual predicted\n",
    "print (predicted)\n",
    "print (y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-279c59148f6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "n_classes = y.shape[-1]\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#creat variable parameters where different perameters are taken\n",
    "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "              {'C': [1, 10, 100, 1000], 'kernel': ['linear'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]}]\n",
    "#creat variable grid_search where variable perameters are passed\n",
    "#estimator = object, step = int or float, optional(default = 1), cv = int, cross-validation or an iterable optional\n",
    "#scoring = string, callable or none, optional, default = none\n",
    "grid_search = GridSearchCV(estimator = svclassifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "#fitting is equal to training. Then, after it is trained, the model can be used to make predictions, usually with a .predict() method call.\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "#for best accurecy\n",
    "best_accuracy = grid_search.best_score_\n",
    "#storing grid_search.best_params__ in variable best_parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "#print(grid_search)\n",
    "print(best_accuracy)\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
